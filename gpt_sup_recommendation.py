import pandas as pd
import psycopg2
import faiss
import openai
import numpy as np
import pickle
from config import OPENAI_API_KEY, FINE_TUNED_MODEL_ID, DB_CONFIG
from sentence_transformers import SentenceTransformer

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = OPENAI_API_KEY
model_name = 'sentence-transformers/all-MiniLM-L6-v2'
embedder = SentenceTransformer(model_name)


# PostgreSQLì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_data_from_db():
    try:
        # PostgreSQL ì—°ê²°
        conn = psycopg2.connect(**DB_CONFIG)
        query = "SELECT id, effects, ingredients, name, warnings FROM api_supplements"
        df = pd.read_sql(query, conn)
        conn.close()
        print("âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
        return df
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def fetch_user_supplements(user_id):
    """ì‚¬ìš©ìê°€ ë³µìš© ì¤‘ì¸ ì˜ì–‘ì œ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        query = f"""
        SELECT supplement_name, ingredients
        FROM user_supplements
        WHERE user_id = {user_id}
        """
        df_user_supplements = pd.read_sql(query, conn)
        conn.close()

        if df_user_supplements.empty:
            print("âš ï¸ ì‚¬ìš©ìê°€ í˜„ì¬ ë³µìš© ì¤‘ì¸ ì˜ì–‘ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        return df_user_supplements

    except Exception as e:
        print(f"âŒ ì‚¬ìš©ì ë³µìš© ì˜ì–‘ì œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_data():
    """ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    print("âœ… ë°ì´í„° ë¡œë“œ ì¤‘...")
    df_items = fetch_data_from_db()

    if df_items is not None:
        """
        # 1. SentenceTransformerë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        model_name = 'sentence-transformers/all-MiniLM-L6-v2'
        embedder = SentenceTransformer(model_name)

        # í…Œì´ë¸” ì»¬ëŸ¼ì— ë§ì¶° í…ìŠ¤íŠ¸ ë°ì´í„° êµ¬ì„±
        text_data = df_items.apply(
            lambda row: f"ì œí’ˆëª…: {row['name']}, íš¨ê³¼: {row['effects']}, ì›ì¬ë£Œ: {row['ingredients']}, ê²½ê³ ì‚¬í•­: {row['warnings']}",
            axis=1
        ).tolist()

        embeddings = embedder.encode(text_data)
        """

        # ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ
        embeddings = np.load("embeddings.npy")
        # ë°ì´í„°í”„ë ˆì„ ë¡œë“œ
        with open("index.pkl", "rb") as f:
            df_items = pickle.load(f)

        # 2. FAISS ì¸ë±ìŠ¤ì— ì„ë² ë”© ì¶”ê°€
        dimension = embeddings.shape[1]  # ì„ë² ë”© ë²¡í„° ì°¨ì›
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings)

        print("âœ… ë°ì´í„° ë¡œë“œ ë° ì„ë² ë”© ìƒì„± ì™„ë£Œ!")

        return df_items, index  # ë°ì´í„°ë¥¼ ë°˜í™˜

    else:
        print("âŒ ë°ì´í„°í”„ë ˆì„ì´ Noneì´ë¯€ë¡œ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return None, None


def search(query, df_items, embedder, index, k=3):
    """ìœ ì‚¬í•œ ì œí’ˆì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜"""
    query_embedding = embedder.encode([query])
    distances, indices = index.search(query_embedding, k)
    results = df_items.iloc[indices[0]]
    return results


def generate_health_summary(survey_data):
    """ì‚¬ìš©ìì˜ ê±´ê°• ì„¤ë¬¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê±´ê°• ìƒíƒœ ìš”ì•½ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    # 1) LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” Context ìƒì„±
    context = "\n".join([
        f"- ì§ˆë¬¸: {item['question']}\n  ì‘ë‹µ: {item['answer']}\n  ìš°ë ¤ì‚¬í•­: {item['concern']}\n  í•„ìš”í•œ ì˜ì–‘ì†Œ: {', '.join(item['required_nutrients']) if isinstance(item['required_nutrients'], list) else item['required_nutrients']}"
        for item in survey_data
    ])

    # 2) GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ì‘ì„±
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ê±´ê°• ë¶„ì„ AIì…ë‹ˆë‹¤. ì•„ë˜ ê±´ê°• ì„¤ë¬¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° í•­ëª©ì— ëŒ€í•´ ë‹µë³€ì„ í•´ì„í•˜ê³ , ê±´ê°• ë¬¸ì œì˜ ì‹¬ê°ë„ì— ë”°ë¼ 1~3ìˆœìœ„ë¡œ ìš°ì„ ìˆœìœ„ë¥¼ ì •ë¦¬í•˜ì„¸ìš”. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”.

    ê±´ê°• ì„¤ë¬¸ ë°ì´í„°:
    {context}
    
    âš ï¸ ë°˜ë“œì‹œ ì•„ë˜ 'ë‹µë³€ í˜•ì‹'ì„ ê·¸ëŒ€ë¡œ ë”°ë¥´ì„¸ìš”. ì¶œë ¥ í˜•ì‹ì´ ì •í™•íˆ ë§ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.
    ë‹µë³€ í˜•ì‹:
    1ìˆœìœ„: "ì‚¬ìš©ìëŠ” [ì‘ë‹µ]í•˜ë¯€ë¡œ, [ìš°ë ¤ì‚¬í•­]ì´ ê°€ì¥ ìš°ë ¤ë©ë‹ˆë‹¤. ì´ì— ë”°ë¼ [í•„ìš”í•œ ì˜ì–‘ì†Œ] ë³´ì¶©ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    2ìˆœìœ„: "ì‚¬ìš©ìëŠ” [ì‘ë‹µ]í•˜ë¯€ë¡œ, [ìš°ë ¤ì‚¬í•­]ì´ ë‘ ë²ˆì§¸ë¡œ ìš°ë ¤ë©ë‹ˆë‹¤. ì´ì— ë”°ë¼ [í•„ìš”í•œ ì˜ì–‘ì†Œ] ë³´ì¶©ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    3ìˆœìœ„: "ì‚¬ìš©ìëŠ” [ì‘ë‹µ]í•˜ë¯€ë¡œ, [ìš°ë ¤ì‚¬í•­]ì´ ì„¸ ë²ˆì§¸ë¡œ ìš°ë ¤ë©ë‹ˆë‹¤. ì´ì— ë”°ë¼ [í•„ìš”í•œ ì˜ì–‘ì†Œ] ë³´ì¶©ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

    ì˜ˆì‹œ ì¶œë ¥:
    1ìˆœìœ„: ì‚¬ìš©ìëŠ” ë§¤ìš° ìì£¼ ì‹œë ¥ì´ ì €í•˜ë˜ê±°ë‚˜ ëˆˆì´ í”¼ë¡œí•´ì§€ë¯€ë¡œ, ì‹œë ¥ ì €í•˜ì™€ ì•ˆêµ¬ ê±´ì¡°ì¦ì´ ê°€ì¥ ìš°ë ¤ë©ë‹ˆë‹¤. ì´ì— ë”°ë¼ ë¹„íƒ€ë¯¼ A, ì˜¤ë©”ê°€-3 ì§€ë°©ì‚° ë³´ì¶©ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    2ìˆœìœ„: ì‚¬ìš©ìëŠ” ìì£¼ ê´€ì ˆì— í†µì¦ì„ ëŠë¼ë¯€ë¡œ, ê´€ì ˆì—¼ê³¼ ì—°ê³¨ ì†ìƒì´ ë‘ ë²ˆì§¸ë¡œ ìš°ë ¤ë©ë‹ˆë‹¤. ì´ì— ë”°ë¼ ê¸€ë£¨ì½”ì‚¬ë¯¼, MSM ë³´ì¶©ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3ìˆœìœ„: ì‚¬ìš©ìëŠ” ê±°ì˜ ì±„ì†Œë¥¼ ì„­ì·¨í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, í•­ì‚°í™” ë¶€ì¡±ê³¼ ë©´ì—­ë ¥ ì €í•˜ê°€ ì„¸ ë²ˆì§¸ë¡œ ìš°ë ¤ë©ë‹ˆë‹¤. ì´ì— ë”°ë¼ ë¹„íƒ€ë¯¼ C, í´ë¦¬í˜ë†€ ë³´ì¶©ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ì‹¬ê°ë„ íŒë‹¨ ê¸°ì¤€:
    - 'ë§¤ìš° ìì£¼ ìˆìŒ' â†’ ë†’ì€ ì‹¬ê°ë„
    - ë§Œì„± ì§ˆí™˜ ë° ê¸°ëŠ¥ì„± ë¬¸ì œ â†’ ìš°ì„ ìˆœìœ„ ë†’ìŒ
    - íŠ¹ì • ì˜ì–‘ì†Œ ê²°í• ìš°ë ¤ ì‹œ â†’ ìš°ì„ ìˆœìœ„ ë†’ìŒ
    - ì‚¬ìš©ìê°€ ëª…ì‹œí•œ â€˜ì˜ì–‘ì œ ì„­ì·¨ ëª©ì â€™ â†’ 1ìˆœìœ„ ê³ ë ¤

    í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¤ê³ , ê° ìˆœìœ„ë³„ë¡œ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì¤‘ë³µëœ ë¬¸êµ¬ ì—†ì´ ëª…í™•í•˜ê²Œ ì„œìˆ í•˜ì„¸ìš”.
    """

    # 3) GPT API í˜¸ì¶œ
    response = openai.chat.completions.create(
        model=FINE_TUNED_MODEL_ID,  # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì‚¬ìš©
        messages=[
            {"role": "system", "content": "You are an AI health expert providing concise health summaries."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=500
    )

    return response.choices[0].message.content


def rag_qa_system(question, df_items, index, user_id):
    """GPT-3.5 Turboë¥¼ ì´ìš©í•œ RAG ì‹œìŠ¤í…œ"""
    if df_items is None or index is None:
        print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € load_data()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return None

    # ì‚¬ìš©ìê°€ ë³µìš© ì¤‘ì¸ ì˜ì–‘ì œ ê°€ì ¸ì˜¤ê¸°
    df_user_supplements = fetch_user_supplements(user_id)

    # 1) Retrieve: ìœ ì‚¬í•œ ë°ì´í„° ê²€ìƒ‰
    search_results = search(question, df_items, embedder, index)

    # 2) Context ìƒì„±
    context = "\n".join(
        f"ì œí’ˆëª…: {row['name']}, íš¨ê³¼: {row['effects']}, ì›ì¬ë£Œ: {row['ingredients']}, ê²½ê³ ì‚¬í•­: {row['warnings']}"
        for _, row in search_results.iterrows()
    )

    # 3) ì‚¬ìš©ì ë³µìš© ì˜ì–‘ì œ ì •ë³´ ìƒì„±
    if df_user_supplements is not None:
        user_supplements_context = "\n".join(
            f"- {row['supplement_name']} (ì£¼ìš” ì„±ë¶„: {row['ingredients']})"
            for _, row in df_user_supplements.iterrows()
        )
    else:
        user_supplements_context = "ì‚¬ìš©ìëŠ” í˜„ì¬ ë³µìš© ì¤‘ì¸ ì˜ì–‘ì œê°€ ì—†ìŠµë‹ˆë‹¤."

    # 4) LLMì— ì§ˆì˜ì™€ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±
    prompt = f"""
    ë‹¹ì‹ ì€ ê±´ê°• ë³´ì¡°ì œ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ ì°¸ê³  ì •ë³´ì˜ 'ì œí’ˆëª…' ì¤‘ì—ì„œ ê°€ì¥ ê´€ë ¨ì´ ìˆëŠ” ì„œë¡œ ë‹¤ë¥¸ ì œí’ˆì„ 3ê°€ì§€ ì°¾ì•„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
    
    ğŸ“Œ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
    1. "ì°¸ê³  ì •ë³´"ì— í¬í•¨ëœ **ì œí’ˆëª…**ë§Œ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤. ì„ì˜ë¡œ ì œí’ˆëª…ì„ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
    2. ì œí’ˆëª…ì€ ë°˜ë“œì‹œ ì •í™•í•˜ê²Œ í‘œê¸°ëœ ì „ì²´ ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: "ê³ ë ¤ì€ë‹¨ ë¹„íƒ€ë¯¼C 1000").
    3. ì°¸ê³  ì •ë³´ì—ì„œ í•´ë‹¹ ì˜ì–‘ì œì˜ 'ì›ì¬ë£Œ' ì¤‘ ê°€ì¥ ë¨¼ì € ë“±ì¥í•˜ëŠ” ì˜ì–‘ì„±ë¶„ 3-5ê°€ì§€ë¥¼ 'ì£¼ìš” ì›ì¬ë£Œ'ë¡œ ì œì‹œí•˜ì„¸ìš”.
    4. íš¨ê³¼ëŠ” ì°¸ê³  ì •ë³´ì—ì„œ í•´ë‹¹ ì˜ì–‘ì œì˜ 'íš¨ê³¼'ë¥¼ ì°¸ê³ í•˜ì—¬ ì´í•´í•˜ê¸° ì‰½ê²Œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    5. ê±´ê°• ë¬¸ì œ, ì¶”ì²œ ì˜ì–‘ì œ, ì£¼ìš” ì›ì¬ë£Œ, íš¨ê³¼ ì¤‘ ëˆ„ë½ëœ í•­ëª©ì´ ìˆìœ¼ë©´ ì•ˆ ë©ë‹ˆë‹¤.

    ì°¸ê³  ì •ë³´:
    {context}

    ì‚¬ìš©ìê°€ ë³µìš© ì¤‘ì¸ ì˜ì–‘ì œ ì •ë³´:
    {user_supplements_context}

    ì§ˆë¬¸: {question}

    ë°˜ë“œì‹œ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©ìì˜ 3ê°€ì§€ ê±´ê°• ë¬¸ì œì— ëŒ€í•´ ê°ê° ì í•©í•œ ì˜ì–‘ì œë¥¼ ì¶”ì²œí•˜ì„¸ìš”:

    1. ê±´ê°• ë¬¸ì œ: (ê±´ê°• ë¬¸ì œ 1ìˆœìœ„)
       ì¶”ì²œ ì˜ì–‘ì œ: (ì œí’ˆëª… 1)
       ì£¼ìš” ì›ì¬ë£Œ: (ì œí’ˆ 1ì˜ ì£¼ìš” ì›ì¬ë£Œ)
       íš¨ê³¼: (ì œí’ˆ 1ì˜ íš¨ê³¼)

    2. ê±´ê°• ë¬¸ì œ: (ê±´ê°• ë¬¸ì œ 2ìˆœìœ„)
       ì¶”ì²œ ì˜ì–‘ì œ: (ì œí’ˆëª… 2)
       ì£¼ìš” ì›ì¬ë£Œ: (ì œí’ˆ 2ì˜ ì£¼ìš” ì›ì¬ë£Œ)
       íš¨ê³¼: (ì œí’ˆ 2ì˜ íš¨ê³¼)

    3. ê±´ê°• ë¬¸ì œ: (ê±´ê°• ë¬¸ì œ 3ìˆœìœ„)
       ì¶”ì²œ ì˜ì–‘ì œ: (ì œí’ˆëª… 3)
       ì£¼ìš” ì›ì¬ë£Œ: (ì œí’ˆ 3ì˜ ì£¼ìš” ì›ì¬ë£Œ)
       íš¨ê³¼: (ì œí’ˆ 3ì˜ íš¨ê³¼)

    ì‚¬ìš©ìì—ê²Œ í•„ìš”í•œ ì˜ì–‘ì„±ë¶„ ì—¬ëŸ¬ ê°€ì§€ê°€ ë™ì‹œì— í¬í•¨ë˜ì–´ ìˆëŠ” ì˜ì–‘ì œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì²œí•˜ì„¸ìš”.
    ì˜ì–‘ì œì˜ ë¶€ì›ë£Œì™€ ì£¼ìš”ì„±ë¶„ì˜ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ê³ ë ¤í•˜ì—¬ ì¶”ì²œí•˜ì„¸ìš”. ê°™ì€ ì£¼ìš” ì„±ë¶„ì´ë¼ë„ ë¶€ì›ë£Œ(ë³´ì¡° ì„±ë¶„)ì— ë”°ë¼ í¡ìˆ˜ìœ¨ê³¼ íš¨ê³¼ì— ì°¨ì´ê°€ ë°œìƒí•©ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´:
        ì¹¼ìŠ˜ ë³´ì¶© â†’ "ë¹„íƒ€ë¯¼ D & K2 í¬í•¨ëœ ì œí’ˆ"ì´ í¡ìˆ˜ìœ¨ ì¦ê°€
        ì² ë¶„ ë³´ì¶© â†’ "ë¹„íƒ€ë¯¼ C í¬í•¨ëœ ì œí’ˆ"ì´ í¡ìˆ˜ìœ¨ ì¦ê°€
        ê´€ì ˆ ê±´ê°• â†’ "ì½œë¼ê² + íˆì•Œë£¨ë¡ ì‚° + MSM" í¬í•¨ëœ ì œí’ˆ ì¶”ì²œ
    âš ï¸ ì‚¬ìš©ìê°€ **í˜„ì¬ ë³µìš© ì¤‘ì¸ ì œí’ˆê³¼ ë™ì¼í•œ ì„±ë¶„**ì„ í¬í•¨í•œ ì˜ì–‘ì œëŠ” ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”.
    """

    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system",
             "content": "You are an assistant that provides specific supplement recommendations based on health summary."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=800
    )
    return response.choices[0].message.content


# ì§ì ‘ ì‹¤í–‰í•  ê²½ìš°ë§Œ load_data() ì‹¤í–‰
if __name__ == "__main__":
    df_items, index = load_data()